# 3.Hadoop运行模式
Hadoop运行模式包括:本地模式、伪分布式模式以及完全分布式模式
Hadoop官方网站:[Hadoop官网](https://hadoop.apache.org/)
## 3.1 本地运行模式
### 3.1.1 官方Grep案例
1. 在hadoop-3.3.0文件下创建一个input文件夹
   - `[hadoop@hadoop01 hadoop-3.3.0]$ mkdir input`
2. 准备文件
   - `[hadoop@hadoop01 hadoop-3.3.0]$ cp etc/hadoop/*.xml input`
3. 运行官方Grep案例
   - `[hadoop@hadoop01 hadoop-3.3.0]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar grep input output 'dfs[a-z.]+'`
4. 查看输出结果
   - `[hadoop@hadoop01 hadoop-3.3.0]$ cat output/*`

### 3.1.2 官方WordCount案例
1. 在hadoop-3.3.0文件下创建一个wcinput文件夹
   - `[hadoop@hadoop01 hadoop-3.3.0]$ mkdir wcinput`
2. 在wcinput文件夹下创建一个wc.input文件
   - `[hadoop@hadoop01 hadoop-3.3.0]$ cd wcinput/`
   - `[hadoop@hadoop01 wcinput]$ touch wc.input`
3. 编辑wc.input文件
   - `[hadoop@hadoop01 wcinput]$ vi wc.input`
   ```
   tianyi huichao lihua
   zhangchen xinheng
   xinbo xinbo
   gaoyang gaoyang yanjing yanjing
   ```
4. 回到Hadoop目录hadoop-3.3.0
   - `cd ..`
5. 执行程序
   - `[hadoop@hadoop01 hadoop-3.3.0]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar wordcount wcinput/ wcoutput`
6. 查看结果
   - `[hadoop@hadoop01 hadoop-3.3.0]$ cd wcoutput/`
   - `[hadoop@hadoop01 wcoutput]$ cat part-r-00000 `
   ```
   gaoyang	2
   huichao	1
   lihua	1
   tianyi	1
   xinbo	2
   xinheng	1
   yanjing	2
   zhangchen	1
   ```

## 3.2 伪分布式运行模式
### 3.2.1 启动HDFS并运行MapReduce程序
1. 分析
   - 配置集群
   - 启动、测试集群增、删、查
   - 执行WordCount案例
2. 执行步骤
   - 2.1 配置集群
     - (a) 配置hadoop-env.sh
       - Linux系统中获取JDK的安装路径:
       ```
       [hadoop@hadoop01 hadoop]$ echo $JAVA_HOME
       /opt/module/jdk1.8.0_181
       ```
       - 修改JAVA_HOME路径:
       ```
       export JAVA_HOME=/opt/module/jdk1.8.0_181
       ```
     - (b) 配置:core-site.xml
     ```
     <configuration>
         <property>
             <name>fs.defaultFS</name>
             <value>hdfs://hadoop01:9000</value>
         </property>
     </configuration>
     ```
     - (c) 配置:hdfs-site.xml
     ```
     <configuration>
         <property>
             <name>dfs.replication</name>
             <value>1</value>
         </property>
     </configuration>
     ```
   - 2.2 启动集群
     - (a) 格式化NameNode
       - `[hadoop@hadoop01 hadoop-3.3.0]$ bin/hdfs namenode -format`
     - (b) 启动NameNode
       - `[hadoop@hadoop01 hadoop-3.3.0]$ sbin/hadoop-daemon.sh start namenode`
     - (c) 启动dataNode
       - `[hadoop@hadoop01 hadoop-3.3.0]$ sbin/hadoop-daemon.sh start datanode`
   - 2.3 查看集群
     - (a) 查看是否启成功
     ```
     [hadoop@hadoop01 logs]$ jps
     12980 NameNode
     15355 Jps
     13181 DataNode
     ```
     - (b) web端查看HDFS文件系统
     ```
     http://IP:9870/dfshealth.html#tab-overview
     ```
     - (c) 查看产生的log日志
     ```
     [hadoop@hadoop01 logs]$ pwd
     /opt/module/hadoop-3.3.0/logs
     [hadoop@hadoop01 logs]$ ls -l
     总用量 104
     -rw-rw-r--. 1 hadoop hadoop 41268 9月  16 13:01 hadoop-hadoop-datanode-hadoop01.log
     -rw-rw-r--. 1 hadoop hadoop   690 9月  14 19:52 hadoop-hadoop-datanode-hadoop01.out
     -rw-rw-r--. 1 hadoop hadoop 46604 9月  16 13:01 hadoop-hadoop-namenode-hadoop01.log
     -rw-rw-r--. 1 hadoop hadoop  6410 9月  15 19:57 hadoop-hadoop-namenode-hadoop01.out
     -rw-rw-r--. 1 hadoop hadoop     0 9月  14 19:38 SecurityAuth-hadoop.audit
     ```
     - (d) 格式化NameNode，需要注意什么？
       - 格式化NameNode，会产生新的集群Id，导致NameNode和DataNode的集群id不一致，集群找不到以往数据。所以，格式NameNode时，一定要先删除data数据和log日志，然后再格式化NameNode。

### 3.2.2 启动YARN并运行MapReduce程序
1. 分析
   - 配置集群在YARN上运行MR
   - 启动、测试集群增、删、查
   - 在YARN上执行WordCount案例
2. 执行步骤
   - 2.1 配置集群
     - (a) 配置yarn-env.sh
       - 修改JAVA_HOME路径:
       ```
       export JAVA_HOME=/opt/module/jdk1.8.0_181
       ```
     - (b) 配置yarn-site.xml
     ```
     <property>
         <name>yarn.nodemanager.aux-services</name>
         <value>mapreduce_shuffle</value>
     </property>
     <property>
         <name>yarn.resourcemanager.hostname</name>
         <value>hadoop01</value>
     </property>
     ```
     - (c) 配置mapred-env.sh
       - 修改JAVA_HOME路径:
       ```
       export JAVA_HOME=/opt/module/jdk1.8.0_181
       ```
     - (d) 配置mapred-site.xml
     ```
     <property>
         <name>mapreduce.framework.name</name>
         <value>yarn</value>
     </property>
     ```
   - 2.2 启动集群
     - (a) 启动前必须保证NameNode和DataNode已经启动
     - (b) 启动ResourceManager
     ```
     [hadoop@hadoop01 hadoop-3.3.0]$ sbin/yarn-daemon.sh start resourcemanager
     ```
     - (c) 启动NodeManager
     ```
     [hadoop@hadoop01 hadoop-3.3.0]$ sbin/yarn-daemon.sh start nodemanager
     ```

### 3.2.3 配置历史服务器
为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下:
1. 配置mapred-site.xml
```
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop01:10020</value>
</property>
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop01:19888</value>
</property>
```
2. 启动历史服务器
```
[hadoop@hadoop01 hadoop-3.3.0]$ sbin/mr-jobhistory-daemon.sh start historyserver
```
3. 查看历史服务器是否启动
```
[hadoop@hadoop01 hadoop-3.3.0]$ jps
```
4. 查看JobHistory
```
http://hadoop01:19888/jobhistory
```

### 3.2.4 配置日志的聚集
日志聚集概念:应用运行完成以后，将程序运行日志信息上传到HDFS系统上。
日志聚集功能好处:可以方便的查看程序运行详情，方便开发调试。
注意:开启日志聚集功能，需要重新启动NodeManager、ResourceManager和HistoryManager。
开启日志聚集功能具体步骤如下:
1. 配置yarn-site.xml
    ```
    <property>
        <name>yarn.log-aggregation-enable</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.log-aggregation.retain-seconds</name>
        <value>604800</value>
    </property>
    ```
2. 关闭NodeManager、ResourceManager和HistoryManager
    ```
    [hadoop@hadoop01 hadoop-3.3.0]$ sbin/mr-jobhistory-daemon.sh stop historyserver
    [hadoop@hadoop01 hadoop-3.3.0]$ sbin/yarn-daemon.sh stop nodemanager
    [hadoop@hadoop01 hadoop-3.3.0]$ sbin/yarn-daemon.sh stop resourcemanager
    ```
3. 启动NodeManager、ResourceManager和HistoryManager
    ```
    [hadoop@hadoop01 hadoop-3.3.0]$ sbin/mr-jobhistory-daemon.sh start historyserver
    [hadoop@hadoop01 hadoop-3.3.0]$ sbin/yarn-daemon.sh start nodemanager
    [hadoop@hadoop01 hadoop-3.3.0]$ sbin/yarn-daemon.sh start resourcemanager
    ```

### 3.2.5 配置文件说明
Hadoop配置文件分为两类:默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。
1. 默认配置文件:  

    | 要获取的默认文件 | 文件存放在Hadoop的jar包中的位置 |
    | :--- | :--- |
    | core-default.xml | hadoop-common-3.3.0.jar/core-default.xml |
    | hdfs-default.xml | hadoop-hdfs-3.3.0.jar/hdfs-default.xml |
    | yarn-default.xml | hadoop-yarn-common-3.3.0.jar/yarn-default.xml |
    | mapred-default.xml | hadoop-mapreduce-client-core-3.3.0.jar/mapred-default.xml |

2. 自定义配置文件:  
core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。

## 3.3 完全分布式运行模式
分析:
   - 准备3台客户机(关闭防火墙、静态IP、主机名称)
   - 安装JDK
   - 配置环境变量
   - 安装Hadoop
   - 配置环境变量
   - 配置集群
   - 单点启动
   - 配置ssh
   - 群起并测试集群

### 3.3.1 虚拟机准备
以hadoop01为标准，克隆hadoop02和hadoop03。

### 3.3.2 集群配置
1. 集群部署规划

    | HostName | hadoop01 | hadoop02 | hadoop03 |
    | :---: | :---: | :---: | :---: |
    | HDFS | NameNode DataNode | DataNode | SecondaryNameNode DataNode |
    | YARN | NodeManager | ResourceManager NodeManager | NodeManager |

2. 配置集群
   - 核心配置文件(core-site.xml)
   ```
   [hadoop@hadoop01 hadoop]$ cd /opt/module/hadoop-3.3.0/etc/hadoop
   [hadoop@hadoop01 hadoop]$ vi core-site.xml
   ```
   ```
   <!-- 指定HDFS中NameNode的地址 -->
   <property>
       <name>fs.defaultFS</name>
       <value>hdfs://hadoop01:9000</value>
   </property>
   ```
   - HDFS配置文件(hadoop-env.sh、hdfs-site.xml)
   ```
   [hadoop@hadoop01 hadoop]$ cd /opt/module/hadooph-3.3.0/etc/hadoop
   [hadoop@hadoop01 hadoop]$ vi hadoop-env.sh
   ```
   ```
   export JAVA_HOME=/opt/module/jdk1.8.0_181
   ```
   ```
   [hadoop@hadoop01 hadoop]$ cd /opt/module/hadoop-3.3.0/etc/hadoop
   [hadoop@hadoop01 hadoop]$ vi hdfs-site.xml
   ```
   ```
   <!-- 副本数 -->
   <property>
       <name>dfs.replication</name>
       <value>3</value>
   </property>
   <!-- 指定Hadoop辅助名称节点主机配置 -->
   <property>
       <name>dfs.namenode.secondary.http-address</name>
       <value>hadoop03:9868</value>
   </property>
   ```
   - YARN配置文件(yarn-env.sh、yarn-site.xml)
   ```
   [hadoop@hadoop01 hadoop]$ cd /opt/module/hadooph-3.3.0/etc/hadoop
   [hadoop@hadoop01 hadoop]$ vi yarn-env.sh
   ```
   ```
   export JAVA_HOME=/opt/module/jdk1.8.0_181
   ```
   ```
   [hadoop@hadoop01 hadoop]$ cd /opt/module/hadoop-3.3.0/etc/hadoop
   [hadoop@hadoop01 hadoop]$ vi yarn-site.xml
   ```
   ```
   <property>
       <name>yarn.nodemanager.aux-services</name>
       <value>mapreduce_shuffle</value>
   </property>
   <property>
       <name>yarn.resourcemanager.hostname</name>
       <value>hadoop02</value>
   </property>
   ```
   - MapReduce配置文件(mapred-env.sh、mapred-site.xml)
   ```
   [hadoop@hadoop01 hadoop]$ cd /opt/module/hadooph-3.3.0/etc/hadoop
   [hadoop@hadoop01 hadoop]$ vi mapred-env.sh
   ```
   ```
   export JAVA_HOME=/opt/module/jdk1.8.0_181
   ```
   ```
   [hadoop@hadoop01 hadoop]$ cd /opt/module/hadoop-3.3.0/etc/hadoop
   [hadoop@hadoop01 hadoop]$ vi mapred-site.xml
   ```
   ```
   <property>
           <name>mapreduce.framework.name</name>
           <value>yarn</value>
   </property>
   ```
3. 在集群上分发配置好的Hadoop配置文件
    ```
    [hadoop@hadoop03 module]$ cd /opt/module/
    [hadoop@hadoop01 module]$ scp -r hadoop-3.3.0/ hadoop@hadoop02:`pwd`
    [hadoop@hadoop01 module]$ scp -r hadoop-3.3.0/ hadoop@hadoop03:`pwd`
    ```
4. 查看文件分发情况
    ```
    [hadoop@hadoop03 module]$ cat /opt/module/hadoop-3.3.0/etc/hadoop/hdfs-site.xml
    ```

### 3.3.3 集群单点启动
1. 如果集群是第一次启动，需要格式化NameNode
    ```
    [hadoop@hadoop01 hadoop-3.3.0]$ hdfs namenode -format
    ```
2. 在hadoop01上启动NameNode
    ```
    [hadoop@hadoop01 hadoop-3.3.0]$ hadoop-daemon.sh start namenode
    ```
3. 在hadoop01、hadoop02、hadoop03上启动DataNode
    ```
    [hadoop@hadoop01 hadoop-3.3.0]$ hadoop-daemon.sh start datanode
    [hadoop@hadoop02 hadoop-3.3.0]$ hadoop-daemon.sh start datanode
    [hadoop@hadoop03 hadoop-3.3.0]$ hadoop-daemon.sh start datanode
    ```

### 3.3.4 免密登录配置
1. 配置ssh
   - ssh基本语法:`ssh IP`
   - 生成公钥和私钥
     - 三台机器都执行:
       - `ssh-keygen -t rsa`
       - 然后敲三个回车，就会生成两个文件id_rsa(私钥)、id_rsa.pub(公钥)
   - 将公钥拷贝到要免密登录的目标机器上
     - 三台机器都执行:
       - `ssh-copy-id hadoop01`
       - `ssh-copy-id hadoop02`
       - `ssh-copy-id hadoop03`
2. .ssh文件夹下(~/.ssh)的文件功能解释

    | 名称 | 功能 |
    | :--- | :--- |
    | known_hosts | 记录ssh访问过计算机的公钥(public key) |
    | id_rsa | 生成的私钥 |
    | id_rsa.pub | 生成的公钥 |
    | authorized_keys | 存放授权过的免密登录服务器公钥 |

### 3.3.5 群起集群
1. 配置slaves
    ```
    [hadoop@hadoop01 hadoop]$  vi /opt/module/hadoop-3.3.0/etc/hadoop/workers
    ```
    ```
    hadoop01
    hadoop02
    hadoop03
    ```
   ```
   [hadoop@hadoop01 hadoop]$ scp workers hadoop@hadoop02:/opt/module/hadoop-3.3.0/etc/hadoop/
   [hadoop@hadoop01 hadoop]$ scp workers hadoop@hadoop03:/opt/module/hadoop-3.3.0/etc/hadoop/
   ```
2. 启动集群
   - 关闭集群中已启动的NameNode和DataNode进程
   ```
   [hadoop@hadoop01 hadoop]$ hadoop-daemon.sh stop namenode
   [hadoop@hadoop01 hadoop]$ hadoop-daemon.sh stop datanode
   [hadoop@hadoop02 hadoop]$ hadoop-daemon.sh stop datanode
   [hadoop@hadoop03 hadoop]$ hadoop-daemon.sh stop datanode
   ```
   - 启动HDSF
   ```
   [hadoop@hadoop01 hadoop]$ start-dfs.sh
   ```
   - 启动YARN
   ```
   [hadoop@hadoop02 ~]$ start-yarn.sh
   ```
3. 集群基本测试
   - 上传文件到集群
     - 上传小文件
     ```
     [hadoop@hadoop01 hadoop-3.3.0]$ hdfs dfs -put /opt/module/hadoop-3.3.0/wcinput/wc.input /
     ```
     - 上传大文件
     ```
     [hadoop@hadoop01 hadoop-3.3.0]$ hdfs dfs -put /opt/software/hadoop-3.3.0.tar.gz /
     ```
   - 上传文件后查看文件存放在什么路径
     - 查看HDFS文件存储路径
     ```
     /tmp/hadoop-hadoop/dfs/data/current/BP-962701229-172.16.198.101-1600513381644/current/finalized/subdir0/subdir0
     ```
     - 查看HDFS在磁盘存储文件内容
     ```
     [hadoop@hadoop01 subdir0]$ cat blk_1073741825
     tianyi huichao lihua
     zhangchen xinheng
     xinbo xinbo
     gaoyang gaoyang yanjing yanjing
     ```

### 3.3.6 集群启动/停止方式总结
1. 各个服务组件逐一启动/停止
   - 分别启动/停止HDFS组件
     - `hadoop-daemon.sh start/stop namenode/datanode/secondarynamenode`
   - 启动/停止YARN
     - `yarn-daemon.sh start/stop resourcemanager/nodemanager`
2. 各个模块分开启动/停止(配置免密登录是前提)
   - 整体启动/停止HDFS
     - `start-dfs.sh/stop-dfs.sh`
   - 整体启动/停止YARN
     - `start-yarn.sh/stop-yarn.sh`

### 3.3.7 集群时间同步
时间同步的方式:找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，比如每隔十分钟，同步一次时间。  
配置时间同步具体实操:
1. 时间服务器配置(必须root用户)
   - 检查ntp是否安装  
   ```
   [root@hadoop01 ~]# rpm -qa | grep ntp
   ```
   ```
   出现如下内容，即为已安装(版本可不一致)
   ntp-4.2.6p5-29.el7.centos.2.x86_64
   ```
   - 修改/etc/ntp.conf配置文件
   ```
   [root@hadoop01 etc]# vi /etc/ntp.conf
   ```
   ```
   #修改集群网段上的所有机器可以从这台机器上查询和同步时间
   restrict 集群网段 mask 255.255.255.0 nomodify notrap
   ```
   ```
   #集群在局域网中，不使用其他互联网上的时间
   #server 0.centos.pool.ntp.org iburst
   #server 1.centos.pool.ntp.org iburst
   #server 2.centos.pool.ntp.org iburst
   #server 3.centos.pool.ntp.org iburst
   ```
   ```
   #当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步
   server 127.127.1.0
   fudge 127.127.1.0 stratum 10
   ```
   - 修改/etc/sysconfig/ntpd配置文件
   ```
   #添加内容如下(让硬件时间和系统时间一起同步)
   SYNC_HWCLOCK=yes
   ```
   - 重新启动ntpd服务
   ```
   [root@hadoop01 etc]# systemctl restart ntpd.service
   ```
   - 设置ntpd服务服务开机启动
   ```
   [root@hadoop01 etc]# systemctl enable ntpd.service
   ```
2. 其他机器配置(必须root用户)
   - 在其他机器配置每小时0分与时间服务器同步一次
   ```
   [root@hadoop02 hadoop]# crontab -e
   ```
   ```
   #编写定时任务如下:
   0 * * * * /usr/sbin/ntpdate hadoop01
   ```
