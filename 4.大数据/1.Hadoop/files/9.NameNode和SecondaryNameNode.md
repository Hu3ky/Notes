# 9.NameNode和SecondaryNameNode
## 9.1 NN和2NN工作机制
思考:NameNode中的元数据是存储在哪里的？  
&emsp;首先，我们做个假设，如果存储在 NameNode 节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。因此产生在磁盘中备份元数据的FsImage。  
&emsp;这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数HDFS 读数据流程据丢失。因此，引入Edits文件(只进行追加操作，效率很高)。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中。这样，一旦NameNode节点断电，可以通过FsImage和Edits的合并，合成元数据。  
&emsp;但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行FsImage和Edits的合并，如果这个操作由NameNode节点完成，又会效率过低。因此，引入一个新的节点SecondaryNameNode，专门用于FsImage和Edits的合并。
1. 第一阶段:NameNode启动
   - 第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。
   - 客户端对元数据进行增删改的请求。
   - NameNode记录操作日志，更新滚动日志。
   - NameNode在内存中对数据进行增删改。
2. 第二阶段:SecondaryNameNode工作
   - SecondaryNameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。
   - SecondaryNameNode请求执行CheckPoint。
   - NameNode滚动正在写的Edits日志。
   - 将滚动前的编辑日志和镜像文件拷贝到SecondaryNameNode。
   - SecondaryNameNode加载编辑日志和镜像文件到内存，并合并。
   - 生成新的镜像文件fsimage.chkpoint。
   - 拷贝fsimage.chkpoint到NameNode。
   - NameNode将fsimage.chkpoint重新命名成fsimage。

## 9.2 Fsimage和Edits解析
1. 概念
   - Fsimage文件:HDFS文件系统元数据的一个永久性的检查点，其中包含HDFS文件系统的所有目录和文件inode的序列化信息。
   - Edits文件:存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到Edits文件中。
   - seen_txid文件:保存的是一个数字，就是最后一个edits_的数字
   - 每次NameNode启动的时候都会将Fsimage文件读入内存，加载Edits里面的更新操作，保证内存中的元数据信息是最新的、同步的，可以看成NameNode启动的时候就将Fsimage和Edits文件进行了合并。
2. 查看oiv和oev命令
    ```
    [hadoop@hadoop01 ~]$ hdfs
    oev   apply the offline edits viewer to an edits file
    oiv   apply the offline fsimage viewer to an fsimage
    ```
3. oiv查看Fsimage文件
   - 基本语法
    ```
    hdfs oiv -p 文件类型 -i 镜像文件 -o 转换后文件输出路径
    ```
4. oev查看Edits文件
   - 基本语法
    ```
    hdfs oev -p 文件类型 -i 编辑日志 -o 转换后文件输出路径
    ```

## 9.3 CheckPoint时间设置
1. 通常情况下,SecondaryNameNode每隔一小时执行一次。(hdfs-default.xml)
    ```
    <property>
        <name>dfs.namenode.checkpoint.period</name>
        <value>3600</value>
    </property>
    ```
2. 一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次。
    ```
    <property>
        <name>dfs.namenode.checkpoint.txns</name>
        <value>1000000</value>
        <description>操作动作次数</description>
        </property>
    <property>
        <name>dfs.namenode.checkpoint.check.period</name>
        <value>60</value>
        <description>1分钟检查一次操作次数</description>
    </property>
    ```

## 9.4 NameNode故障处理
NameNode故障后，可以采用如下两种方法恢复数据。  
方法一:将SecondaryNameNode中数据拷贝到NameNode存储数据的目录;
1. kill -9 NameNode 进程
    ```
    [hadoop@hadoop01 dfs]$ kill -9 NameNodePID
    ```
2. 删除NameNode存储的数据
    ```
    [hadoop@hadoop01 dfs]$ rm -rf /tmp/hadoop-hadoop/dfs/name/*
    ```
3. 拷贝SecondaryNameNode中数据到原NameNode存储数据目录
    ```
    [hadoop@hadoop03 dfs]$ scp -r namesecondary/* hadoop@hadoop01:/tmp/hadoop-hadoop/dfs/name
    ```
4. 重新启动NameNode
    ```
    [hadoop@hadoop01 dfs]$ /opt/module/hadoop-3.3.0/sbin/hadoop-daemon.sh start namenode
    ```
方法二:使用-importCheckpoint选项启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中。
1. 修改hdfs-site.xml
    ```
    <property>
        <name>dfs.namenode.checkpoint.period</name>
        <value>120</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/tmp/hadoop-hadoop/dfs/name</value>
    </property>
    ```
2. kill -9 NameNode 进程
    ```
    [hadoop@hadoop01 dfs]$ kill -9 NameNodePID
    ```
3. 删除NameNode存储的数据
    ```
    [hadoop@hadoop01 dfs]$ rm -rf /tmp/hadoop-hadoop/dfs/name/*
    ```
4. 如果SecondaryNameNode不和NameNode在一个主机节点上，需要将SecondaryNameNode存储数据的目录拷贝到NameNode存储数据的平级目录，并删除in_use.lock文件
    ```
    [hadoop@hadoop01 dfs]$ scp -r hadoop@hadoop03:/tmp/hadoop-hadoop/dfs/namesecondary/ /tmp/hadoop-hadoop/dfs/
    [hadoop@hadoop01 dfs]$ rm -rf /tmp/hadoop-hadoop/dfs/namesecondary/in_use.lock
    ```
5. 导入检查点数据(等待一会ctrl+c结束掉)
    ```
    [hadoop@hadoop01 dfs]$ hdfs namenode -importCheckpoint
    ```
6. 启动NameNode
    ```
    [hadoop@hadoop01 dfs]$ /opt/module/hadoop-3.3.0/sbin/hadoop-daemon.sh start namenode
    ```

## 9.5 集群安全模式
1. 概述
   - NameNode启动
     - NameNode启动时，首先将镜像文件(Fsimage)载入内存，并执行编辑日志(Edits)中的各项操作。一旦在内存中成功建立文件系统元数据的映像，则创建一个新的Fsimage文件和一个空的编辑日志。此时，NameNode开始监听DataNode请求。这个过程期间，NameNode一直运行在安全模式，即NameNode的文件系统对于客户端来说是只读的。
   - DataNode启动
     - 系统中的数据块的位置并不是由NameNode维护的，而是以块列表的形式存储在DataNode中。在系统的正常操作期间，NameNode会在内存中保留所有块位置的映射信息。在安全模式下，各个DataNode会向 NameNode发送最新的块列表信息，NameNode了解到足够多的块位置信息之后，即可高效运行文件系统。
   - 安全模式退出判断
     - 如果满足“最小副本条件”，NameNode会在30秒钟之后就退出安全模式。所谓的最小副本条件指的是在整个文件系统中99.9%的块满足最小副本级别(默认值:dfs.replication.min=1)。在启动一个刚刚格式化的HDFS集群时，因为系统中还没有任何块，所以NameNode不会进入安全模式。
2. 基本语法
集群处于安全模式，不能执行重要操作(写操作)。集群启动完成后，自动退出安全模式。
    ```
    hdfs dfsadmin -safemode get      (功能描述:查看安全模式状态)
    hdfs dfsadmin -safemode enter    (功能描述:进入安全模式状态)
    hdfs dfsadmin -safemode leave    (功能描述:离开安全模式状态)
    hdfs dfsadmin -safemode wait     (功能描述:等待安全模式状态)
    ```
3. 案例
模拟等待安全模式
   - 查看当前模式
    ```
    [hadoop@hadoop01 current]$ hdfs dfsadmin -safemode get
    Safe mode is OFF
    ```
   - 先进入安全模式
    ```
    [hadoop@hadoop01 hadoop-3.3.0]$ hdfs dfsadmin -safemode enter
    Safe mode is ON
    ```
   - 创建并执行下面的脚本
    ```
    在/opt/module/hadoop-3.3.0路径上，编辑一个脚本safemode.sh
    [hadoop@hadoop01 hadoop-3.3.0]$ touch safemode.sh
    [hadoop@hadoop01 hadoop-3.3.0]$ vi safemode.sh 
    #!/bin/bash
    hdfs dfsadmin -safemode wait
    hdfs dfs -put /opt/module/hadoop-3.3.0/README.txt /
    [hadoop@hadoop01 hadoop-3.3.0]$ sh safemode.sh 
    ```
   - 再打开一个窗口，执行
    ```
    [hadoop@hadoop01 ~]$ hdfs dfsadmin -safemode leave
    ```
   - 观察
    ```
    上一个窗口:
    [hadoop@hadoop01 hadoop-3.3.0]$ sh safemode.sh 
    Safe mode is OFF
    并且HDFS集群上已经有上传的数据了。
    ```

## 9.6 NameNode多目录配置
1. NameNode的本地目录可以配置称多个，且每个目录存放目录相同，增加了可靠性
2. 具体配置如下
   - 在hdfs-site.xml文件中增加如下内容
    ```
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///${hadoop.tmp.dir}/dfs/name1,file:///${hadoop.tmp.dir}/dfs/name2</value>
    </property>
    ```
   - 停止集群，删除data和logs中所有数据。
    ```
    [hadoop@hadoop01 sbin]$ rm -rf /opt/module/hadoop-3.3.0/logs/ /tmp/hadoop-hadoop/
    [hadoop@hadoop02 sbin]$ rm -rf /opt/module/hadoop-3.3.0/logs/ /tmp/hadoop-hadoop/
    [hadoop@hadoop03 sbin]$ rm -rf /opt/module/hadoop-3.3.0/logs/ /tmp/hadoop-hadoop/
    ```
   - 格式化集群并启动。
    ```
    [hadoop@hadoop01 ~]$ hdfs namenode -format
    [hadoop@hadoop01 ~]$ /opt/module/hadoop-3.3.0/sbin/start-dfs.sh 
    ```
   - 查看结果
    ```
    [hadoop@hadoop01 ~]$ ls -al /tmp/hadoop-hadoop/dfs/
    总用量 20
    drwxrwxr-x. 5 hadoop hadoop 4096 10月 19 18:53 .
    drwxrwxr-x. 3 hadoop hadoop 4096 10月 19 18:51 ..
    drwx------. 3 hadoop hadoop 4096 10月 19 18:53 data
    drwxrwxr-x. 3 hadoop hadoop 4096 10月 19 18:53 name1
    drwxrwxr-x. 3 hadoop hadoop 4096 10月 19 18:53 name2
    ```
