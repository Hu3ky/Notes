# 11.HDFS2.X新特性
## 11.1 集群间数据拷贝
1. scp实现两个远程主机之间的文件复制:
   - `scp 源文件 目标文件`
2. 采用distcp命令实现两个Hadoop集群之间的递归数据复制:
   - `hadoop distcp 源文件 目标文件`

## 11.2 小文件存档
1. HDFS存储小文件弊端  
每个文件均按块存储，每个块的元数据存储在NameNode的内存中，因此HDFS存储小文件会非常低效。因为大量的小文件会耗尽NameNode中的大部分内存。但注意，存储小文件所需要的磁盘容量和数据块的大小无关。例如，一个1MB的文件设置为128MB的块存储，实际使用的是1MB的磁盘空间，而不是128MB。
2. 解决存储小文件办法之一  
HDFS存档文件或HAR文件，是一个更高效的文件存档工具，它将文件存入HDFS块，在减少NameNode内存使用的同时，允许对文件进行透明的访问。具体来说，HDFS存档文件对内还是一个一个独立文件，对NameNode而言却是一个整体，减少了NameNode的内存。
3. 案例实操
   - 需要启动YARN进程
     - `[hadoop@hadoop02 sbin]$ start-yarn.sh`
   - 归档文件:把/user/hadoop/input目录里面的所有文件归档成一个叫input.har的归档文件，并把归档后文件存储到/user/hadoop/output路径下。
     - `[hadoop@hadoop01 hadoop]$ hadoop archive -archiveName input.har -p /user/hadoop/input /user/hadoop/output`
   - 查看归档
    ```
    [hadoop@hadoop01 hadoop]$ hadoop fs -ls /user/hadoop/output/input.har
    Found 4 items
    -rw-r--r--   3 hadoop supergroup          0 2020-10-27 16:03 /user/hadoop/output/input.har/_SUCCESS
    -rw-r--r--   3 hadoop supergroup        304 2020-10-27 16:03 /user/hadoop/output/input.har/_index
    -rw-r--r--   3 hadoop supergroup         23 2020-10-27 16:03 /user/hadoop/output/input.har/_masterindex
    -rw-r--r--   3 hadoop supergroup         92 2020-10-27 16:03 /user/hadoop/output/input.har/part-0
    [hadoop@hadoop01 hadoop]$ hadoop fs -ls har:///user/hadoop/output/input.har
    Found 3 items
    -rw-r--r--   3 hadoop supergroup         32 2020-10-27 15:50 har:///user/hadoop/output/input.har/panjinlian.txt
    -rw-r--r--   3 hadoop supergroup         14 2020-10-27 15:50 har:///user/hadoop/output/input.har/ximenqing.txt
    -rw-r--r--   3 hadoop supergroup         46 2020-10-27 15:50 har:///user/hadoop/output/input.har/zaiyiqi.txt
    ```
  - 解归档文件
    ```
    [hadoop@hadoop01 hadoop]$ hadoop fs -cp har:///user/hadoop/output/input.har/* /user/hadoop
    [hadoop@hadoop01 hadoop]$ hadoop fs -ls /user/hadoop
    Found 5 items
    drwxr-xr-x   - hadoop supergroup          0 2020-10-27 15:50 /user/hadoop/input
    drwxr-xr-x   - hadoop supergroup          0 2020-10-27 16:03 /user/hadoop/output
    -rw-r--r--   3 hadoop supergroup         32 2020-10-27 16:08 /user/hadoop/panjinlian.txt
    -rw-r--r--   3 hadoop supergroup         14 2020-10-27 16:08 /user/hadoop/ximenqing.txt
    -rw-r--r--   3 hadoop supergroup         46 2020-10-27 16:08 /user/hadoop/zaiyiqi.txt
    ```

## 11.3 回收站
开启回收站功能，可以将删除的文件在不超时的情况下，恢复原数据，起到防止误删除、备份等作用。  
1. 开启回收站功能参数说明:
   - 默认值fs.trash.interval=0，0表示禁用回收站;其他值表示设置文件的存活时间。
   - 默认值fs.trash.checkpoint.interval=0，检查回收站的间隔时间。如果该值为0，则该值设置和fs.trash.interval的参数值相等
   - 要求fs.trash.checkpoint.interval<=fs.trash.interval。
2. 回收站工作机制:
   - 启用回收站:修改 core-site.xml，配置垃圾回收时间为1分钟。
    ```
    <property>
        <name>fs.trash.interval</name>
        <value>1</value>
    </property>
    ```
   - 查看回收站:回收站在集群中的路径:/user/hadoop/.Trash/....
   - 修改访问垃圾回收站用户名称:进入垃圾回收站用户名称，默认是dr.who，修改为hadoop用户
    ```
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>atguigu</value>
    </property>
    ```
   - 通过程序删除的文件不会经过回收站，需要调用moveToTrash()才进入回收站
    ```
    Trash trash = New Trash(conf);
    trash.moveToTrash(path);
    ```
   - 恢复回收站数据
   - 清空回收站

## 11.4 快照管理
1. 快照管理
   - 快照相当于对目录做一个备份。并不会立即复制所有文件，而是记录文件变化。  
    ```
    hdfs dfsadmin -allowSnapshot 路径 (功能描述:开启指定目录的快照功能)
    hdfs dfsadmin -disallowSnapshot 路径 (功能描述:禁用指定目录的快照功能，默认是禁用)
    hdfs dfs -createSnapshot 路径 (功能描述:对目录创建快照)
    hdfs dfs -createSnapshot 路径 名称 (功能描述:指定名称创建快照)
    hdfs dfs -renameSnapshot 路径 旧名称 新名称 (功能描述:重命名快照)
    hdfs lsSnapshottableDir (功能描述:列出当前用户所有可快照目录)
    hdfs snapshotDiff 路径1 路径2 (功能描述:比较两个快照目录的不同之处)
    hdfs dfs -deleteSnapshot <path> <snapshotName> (功能描述:删除快照)
    ```
2. 案例实操
   - 开启指定目录的快照功能
    ```
    [hadoop@hadoop01 hadoop]$ hdfs dfsadmin -allowSnapshot /user/hadoop/input
    Allowing snapshot on /user/hadoop/input succeeded
    ```
   - 对目录创建快照
    ```
    [hadoop@hadoop01 hadoop]$ hdfs dfs -createSnapshot /user/hadoop/input
    Created snapshot /user/hadoop/input/.snapshot/s20201027-202932.239
    ```
   - 指定名称创建快照
    ```
    [hadoop@hadoop01 hadoop]$ hdfs dfs -createSnapshot /user/hadoop/input snapshot1
    Created snapshot /user/hadoop/input/.snapshot/snapshot1
    ```
   - 重命名快照
    ```
    [hadoop@hadoop01 hadoop]$ hdfs dfs -renameSnapshot /user/hadoop/input snapshot1 snapshot2
    Renamed snapshot snapshot1 to snapshot2 under hdfs://hadoop01:9000/user/hadoop/input
    ```
   - 列出当前用户所有可快照目录
    ```
    [hadoop@hadoop01 hadoop]$ hdfs lsSnapshottableDir
    drwxr-xr-x 0 hadoop supergroup 0 2020-10-27 20:30 2 65536 /user/hadoop/input
    ```
   - 比较两个快照目录的不同之处
    ```
    [hadoop@hadoop01 hadoop]$ hdfs snapshotDiff /user/hadoop/input . .snapshot/snapshot2
    Difference between current directory and snapshot snapshot2 under directory /user/hadoop/input:

    ```
   - 恢复快照
    ```
    [hadoop@hadoop01 hadoop]$ hdfs dfs -cp /user/hadoop/input/.snapshot/snapshot2/ /user/hadoop/input
    ```
