# 10.DataNode
## 10.1 DataNode工作机制
1. 一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。
2. DataNode 启动后向NameNode注册，通过后，周期性(1小时)的向NameNode上报所有的块信息。
3. 心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。
4. 集群运行中可以安全加入和退出一些机器。

## 10.2 数据完整性
如下是DataNode节点保证数据完整性的方法
1. 当DataNode读取Block的时候，它会计算CheckSum。
2. 如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。
3. Client读取其他DataNode上的Block。
4. DataNode在其文件创建后周期验证CheckSum。

## 10.3 掉线时限参数设置
1. DataNode进程死亡或者网络故障造成DataNode无法与NameNode通信。
2. NameNode不会立即把该节点判定为死亡，要经过一段时间，这段时间暂称作超时时长。
3. HDFS默认的超时时长为10分钟+30秒。
4. 如果定义超时时间为TimeOut，则超时时长的计算公式为:  
   `TimeOut = 2 * dfs.namenode.heartbeat.recheck-interval + 10 * dfs.heartbeat.interval。`  
   而默认的dfs.namenode.heartbeat.recheck-interval大小为5分钟，dfs.heartbeat.interval默认为3秒。

## 10.4 服役新数据节点
0. 需求
随着公司业务的增长，数据量越来越大，原有的数据节点的容量已经不能满足存储数据的需求，需要在原有集群基础上动态添加新的数据节点。
1. 环境准备
   - 在hadoop03主机上再克隆一台hadoop04主机
   - 修改IP地址和主机名称
   - 删除原来HDFS文件系统留存的文件
   - source一下配置文件
2. 服役新节点具体步骤
   - 直接启动DataNode，即可关联到集群
   - 在hadoop04上上传文件
   - 如果数据不均衡，可以用命令实现集群的再平衡`start-balancer.sh`

## 10.5 退役旧数据节点
### 10.5.1 添加白名单
添加到白名单的主机节点，都允许访问 NameNode，不在白名单的主机节点，都会被退出。  
配置白名单的具体步骤如下:  
1. 在NameNode的/opt/module/hadoop-3.3.0/etc/hadoop目录下创建dfs.hosts文件,并添加主机名称。
2. 在NameNode的hdfs-site.xml配置文件中增加dfs.hosts属性
    ```
    <property>
        <name>dfs.hosts</name>
        <value>/opt/module/hadoop-3.3.0/etc/hadoop/dfs.hosts</value>
    </property>
    ```
3. 配置文件分发
4. 刷新NameNode`hdfs dfsadmin -refreshNodes`
5. 更新ResourceManager节点`yarn rmadmin -refreshNodes`
6. 如果数据不均衡，可以用命令实现集群的再平衡`start-balancer.sh`

### 10.5.2 黑名单退役
在黑名单上面的主机都会被强制退出。  
1. 在NameNode的/opt/module/hadoop-3.3.0/etc/hadoop目录下创建dfs.hosts.exclude文件,并添加要退役的节点的主机名
2. 在NameNode的hdfs-site.xml配置文件中增加dfs.hosts.exclude属性
    ```
    <property>
        <name>dfs.hosts.exclude</name>
        <value>/opt/module/hadoop-3.3.0/etc/hadoop/dfs.hosts.exclude</value>
    </property>
    ```
3. 刷新NameNode`hdfs dfsadmin -refreshNodes`、刷新ResourceManager`yarn rmadmin -refreshNodes`
4. 检查Web浏览器，退役节点的状态为decommission in progress(退役中)，说明数据节点正在复制块到其他节点.
5. 等待退役节点状态为decommissioned(所有块已经复制完成)，停止该节点及节点资源管理器。注意:如果副本数是3，服役的节点小于等于3，是不能退役成功的，需要修改副本数后才能退役.
6. 如果数据不均衡，可以用命令实现集群的再平衡`start-balancer.sh`

## 10.6 Datanode多目录配置
1. DataNode也可以配置成多个目录，每个目录存储的数据不一样。即:数据不是副本。
2. 具体配置如下(hdfs-site.xml)
    ```
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///${hadoop.tmp.dir}/dfs/data1,file:///${hadoop.tmp.dir}/dfs/data2</value>
    </property>
    ```
